---
layout: post
title: "LSCP"
author: "Lin"
---

# LSCP: Locally Selective Combination in Parallel Outlier Ensembles

## 核心想法：

多个异常检测器在全训练集上Ensemble生成假标签，在每个测试点的局部区域内(由Ensemble kNN得到)进行二次计算，得到的结果与假标签比，选取相关系数最高的检测器作为测试点的最终输出。

## 算法步骤：

![flowchart](/sdnanjing.github.io/assets/imgs/flowchart.png)

### 1. 选取 Base Detector

选取任意多的异常检测算法作为Base Detector，其中可选取多个有不同超参的相同异常检测算法，如选取三个有不同$minPts$的LOF检测器，每个检测器分别对所有样本打分，得到的Outlier Score进行归一化，score越大越可能是异常，由此获得Outlier Score矩阵  $O(X_{train})=[C_1(X_{train}),...,C_r(X_{train})]\in \mathbb{R}^{n\times R}$,其中$C_r$代表第$r$个Base Detector，n是训练样本数，R是Base Detector的数量。

### 2. 生成假标签

用Outlier Score的最大值或平均值，给异常分最高的一定比例的点打上异常标签，作为ground truth, $target = \phi (O(X_{train}))\in \mathbb{R} ^{n\times 1}$, 其中$\phi$表示是去平均还是取最大值的函数。 

### 3. 定义 Local Region

对于每个测试数据点$X_{test}^{(j)}$，我们选取该点周围的部分训练样本的点，称为 Local Region $\psi _j$, 在这个子区域里重新计算判定测试数据点是否为异常。$\psi _j$由Ensemble kNN的方式寻找，过程如下：

(1) 随机选取 $t$ 组$[\frac{d}{2}, d]$维的特征子空间做实验

(2) 每一组的该测试点的K近邻的点由欧氏距离计算获得

(3) 若同一个训练样本点在超过 $\frac{t}{2}$ 组K近邻实验里出现，则加入到该测试点的Local Region中。

于是我们获得了每个样本点的Local Region:$psi_j = \\{x_i\|x_i\in X_{train}, x_i\in kNN_{ens}^{(j)}\\}$

### 4. 模型选择和组合

对每个测试点，其local region的ground truth 为 $target^{\psi_j}=\\{target_{x_i}\|x_i \in \psi_j\\}\in \mathbb{R}^{\|\psi_j\| \times 1}$ , 其中$\|\psi \_j\|$ 为该local region中的点的数量。同样，local region中的点的Outlier Score为$O(\psi_j)=[C_1(\psi_j),...,C_r(\psi_j)]\in \mathbb{R}^{\|\psi_j\| \times R}$. 

接下来我们对Local Region中的点用所有的Base Detector进行重新计算得到$C_r(X_{train}^{\psi_j})$，与之前给定的标签 $$target^{\psi_j}$$作比较，计算Person correlation。相关系数最高的探测器 $$C_r^*$$ 被选为测试点的最有说服力的异常检测器，其结果 $C_r^*(X_{test}^{(j)})$ 作为该点最终的异常值。

选取一个Base Detector最为输出存在较大风险，因此设定一个参数b，可以选择最终参与最终输出的Detector的数量，用AOM或MOA的方式融合多个Detector的结果。

![algorithm](/sdnanjing.github.io/assets/imgs/algorithm.png)

